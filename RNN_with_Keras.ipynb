{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4AFhDuktpX8"
   },
   "source": [
    "# RNN(Recurrent Neural Networks)\n",
    "\n",
    "- exploit the sequential nature of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2282,
     "status": "ok",
     "timestamp": 1563279449591,
     "user": {
      "displayName": "류성민",
      "photoUrl": "",
      "userId": "06574757729193647472"
     },
     "user_tz": -540
    },
    "id": "AsOMERcUtpX9",
    "outputId": "0f81ccf4-007a-46f5-b5bc-4816792481be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50879,
     "status": "ok",
     "timestamp": 1563279513043,
     "user": {
      "displayName": "류성민",
      "photoUrl": "",
      "userId": "06574757729193647472"
     },
     "user_tz": -540
    },
    "id": "2cWEErkFt23k",
    "outputId": "53eb5679-e764-4cb3-c0fd-6c3ccb2a9366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "mount.txt  RNN_study  val_data.ipynb\n",
      "ls: cannot access './drive/My Drive/Colab Notebooks/val': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls '/content/drive/My Drive/Colab Notebooks'\n",
    "!ls './drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1563279585101,
     "user": {
      "displayName": "류성민",
      "photoUrl": "",
      "userId": "06574757729193647472"
     },
     "user_tz": -540
    },
    "id": "IA98LE7kuTbN",
    "outputId": "ed4dc91b-7f6d-44f9-9293-31f1373f738d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.txt\tREADME.md  RNN_with_Keras.ipynb  RNN_with_Pytorch.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls './drive/My Drive/Colab Notebooks/RNN_study'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTtLF1UQtpYC"
   },
   "outputs": [],
   "source": [
    "fin = open('./drive/My Drive/Colab Notebooks/RNN_study/11.txt','rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\",\"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pU-isohMtpYE"
   },
   "outputs": [],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "doA9AyEitpYH"
   },
   "outputs": [],
   "source": [
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoiefurXtpYJ"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrE5VN0ntpYL",
    "outputId": "369fdd5f-1bf8-487c-f6bf-cce0bd003f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161793, 10, 57)\n",
      "(161793, 57)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1563280316699,
     "user": {
      "displayName": "류성민",
      "photoUrl": "",
      "userId": "06574757729193647472"
     },
     "user_tz": -540
    },
    "id": "YPzDww1SxE08",
    "outputId": "c8228480-f6e3-4835-9e77-149369260742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False  True False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False  True False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False]]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 996,
     "status": "ok",
     "timestamp": 1563279649200,
     "user": {
      "displayName": "류성민",
      "photoUrl": "",
      "userId": "06574757729193647472"
     },
     "user_tz": -540
    },
    "id": "5lkxzuXitpYO",
    "outputId": "1d14ad18-03f3-4450-99be-ee9b6d7fbaa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 12:21:49.887607 140180111046528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0716 12:21:49.935792 140180111046528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0716 12:21:49.944966 140180111046528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0716 12:21:50.094873 140180111046528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0716 12:21:50.132376 140180111046528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "# Define a model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False, input_shape=(SEQLEN, nb_chars), unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Configure the model for training\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 232404,
     "status": "ok",
     "timestamp": 1563280001200,
     "user": {
      "displayName": "류성민",
      "photoUrl": "",
      "userId": "06574757729193647472"
     },
     "user_tz": -540
    },
    "id": "ZBtdCCAQtpYS",
    "outputId": "5c464b94-8ab7-45c2-d0c7-87c4d1cc933f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.6672\n",
      "Generating from seed:  hought at \n",
      "hought at the don of the project gutenberg-tm ereat der get on the patter was to her head to her head to her h\n",
      " ==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 57us/step - loss: 1.6347\n",
      "Generating from seed:  aid the ha\n",
      "aid the hatter the mock turtle the courted to she was and the this aller all the this aller all the this aller\n",
      " ==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 57us/step - loss: 1.6059\n",
      "Generating from seed:   then i wo\n",
      " then i wond in the mouse to the parse on the mory with a look the mory with a look the mory with a look the m\n",
      " ==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 57us/step - loss: 1.5807\n",
      "Generating from seed:  g \"come up\n",
      "g \"come up and said to she said to herself it all the gryphon. 'i won't you consed to the gryphon. 'i won't yo\n",
      " ==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.5596\n",
      "Generating from seed:  y deeply w\n",
      "y deeply with the sardened the mock turtle with the sardened the mock turtle with the sardened the mock turtle\n",
      " ==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.5404\n",
      "Generating from seed:  ed for it \n",
      "ed for it was stread the room and the dormouse was she was so much a little be a read the dormouse was she was\n",
      " ==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.5222\n",
      "Generating from seed:  ht she, 'w\n",
      "ht she, 'what i shall he say the poor alice, would her here was to see that the was a look a conered to the do\n",
      " ==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.5075\n",
      "Generating from seed:  rns, quarr\n",
      "rns, quarred the distributions the was got to the distributions the was got to the distributions the was got t\n",
      " ==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.4929\n",
      "Generating from seed:  ame height\n",
      "ame height as the work to the sabbet of course of the white rabbit as the work to the sabbet of course of the \n",
      " ==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.4804\n",
      "Generating from seed:  'i only to\n",
      "'i only to donce to the door all the fordous to her for the course,' said the dorrous everything and she sere \n",
      " ==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.4682\n",
      "Generating from seed:  alf hoping\n",
      "alf hoping to the got to the got to the got to the got to the got to the got to the got to the got to the got \n",
      " ==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 58us/step - loss: 1.4580\n",
      "Generating from seed:  rowing, an\n",
      "rowing, and she was the mock turtle think it was the mock turtle think it was the mock turtle think it was the\n",
      " ==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 57us/step - loss: 1.4478\n",
      "Generating from seed:  o go throu\n",
      "o go through the began to the gryphon and she had been the other side the gay or the hatter with the gryphon a\n",
      " ==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 57us/step - loss: 1.4390\n",
      "Generating from seed:   alice,) a\n",
      " alice,) and the me the me the me the me the me the me the me the me the me the me the me the me the me the me\n",
      " ==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.4304\n",
      "Generating from seed:  t particul\n",
      "t particule she could on the project gutenberg-tm little sat the mock turtle in a surpression of the thing it \n",
      " ==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 55us/step - loss: 1.4222\n",
      "Generating from seed:   garden: t\n",
      " garden: the marte of the mart of the such a distried the march hare was not a mouted the mouse to the door al\n",
      " ==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.4145\n",
      "Generating from seed:  ct is, you\n",
      "ct is, you know.' 'i don't the was a conversations with the was a conversations with the was a conversations w\n",
      " ==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.4083\n",
      "Generating from seed:     *    * \n",
      "   *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    * \n",
      " ==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 55us/step - loss: 1.3997\n",
      "Generating from seed:  r side of \n",
      "r side of the mouse in a long the shook alice the poor alice, and the mouse in a long the shook alice the poor\n",
      " ==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 55us/step - loss: 1.3950\n",
      "Generating from seed:  s it puffe\n",
      "s it puffed to her hand in a more the sate the mouse in a low must be a read to the mock turtle some of the to\n",
      " ==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.3879\n",
      "Generating from seed:  l in sight\n",
      "l in sight all ran first as she had not at all who said to the door as the gryphon went on off the march hare \n",
      " ==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.3830\n",
      "Generating from seed:  s night an\n",
      "s night and the mock turtle you may it was a little door of the tore the sate the sate the sate the sate the s\n",
      " ==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.3786\n",
      "Generating from seed:  u see, as \n",
      "u see, as she was not a conversation of the toll what to the pigeon, and the mock turtle. 'we don't be a conse\n",
      " ==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 55us/step - loss: 1.3727\n",
      "Generating from seed:  , and in h\n",
      ", and in her hand the mock turtle she could not a little should be a copying on engly the project gutenberg-tm\n",
      " ==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "161793/161793 [==============================] - 9s 56us/step - loss: 1.3682\n",
      "Generating from seed:  the knave \n",
      "the knave of the told as the trimed the queen of the teamed the reased all the thing the white rabbit do you t\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"\\n\",\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" %(iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: \", test_chars)\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        #move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybj0sn_ktpYU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RNN_with_Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
